## {{nfact}} Factors

### Imputation of Missing Items ({{nfact}} factors)

include reference on why imputation is better than removing
observations, pairwise removing is biased, using means isn't good.

Categorical missing values using multiple Correspondence Analysis (also called Missing Fuzzy Average method)
Josseet al (201
0)
``` {r, impute{{nfact}}, results="asis", echo=FALSE}

imputationResults{{nfact}} <- imputeMCA(ddOrd{{nfact}})
postImputedFactors{{nfact}} <- imputationResults{{nfact}}$completeObs
save(postImputedFactors{{nfact}}, file=paste0("data/imputedFactors2.2.", {{nfact}}, ".Rda"))
imputedChar{{nfact}} <- lapply(postImputedFactors{{nfact}}, as.character)
imputedNumeric{{nfact}} <- lapply(imputedChar{{nfact}}, as.numeric)

imputedNumericDF{{nfact}} <- data.frame(imputedNumeric{{nfact}})
save(imputedNumericDF{{nfact}}, file="data/imputedNumericDF2.2.{{nfact}}.Rda")

```

### {{nfact}}-Factors: Pre-Imputation Tests for Data Suitability for Factor Analysis

#### Bartlett's Test of Sphericity

This function tests whether a correlation matrix is significantly different from an identity matrix (Bartlett, 1951). If the Bartlett's test is not significant, the correlation matrix is not suitable for factor analysis because the variables show too little covariance.  

``` {r, preBartlett{{nfact}}, results="asis", echo=FALSE}
### calculate polychoric correlation

preImputedCor{{nfact}} <- polychoric(ddNum{{nfact}},
                                     smooth = TRUE,
                                     correct = 0.01)
preImputedCor{{nfact}} <- round(preImputedCor{{nfact}}$rho, 3)
write.csv(preImputedCor{{nfact}}, file=paste0("data/polychoricCorrelations2.2.{{nfact}}", {{nfact}}, ".csv"), quote=FALSE, row.names=FALSE)

preBartlett{{nfact}} <- cortest.bartlett(preImputedCor{{nfact}},
                                         n = nrow(ddOrd{{nfact}}))

```

This is a test that the matrix is an identity matrix. This would mean
that the correlations were not significantly different from 0.
If it's not significant, the matrix is not suitable because 
the variables show too little covariance.  

The chi-squared for the Bartlett test is 
`r preBartlett{{nfact}}$chisq` with
`r preBartlett{{nfact}}$df` DF, p = 
`r format(preBartlett{{nfact}}$p.value, scientific=TRUE)`.

#### Kaiser-Meyer-Olkin Criterion (KMO)

From EFAtools::KMO documentation:

> The KMO represents the degree to which each observed variable is predicted by the other variables in the dataset and with this indicates the suitability for factor analysis  

The numeric version of the dataset is used because stats::cor is used to find
the correlation and it requires numeric input. Used option for 
Spearman correlation because of ordered variables.  


``` {r, KMOpremputed{{nfact}}, results="asis", echo=FALSE}
KMOoutput{{nfact}} <- KMO(ddNum{{nfact}}, cor_method = "spearman")
KMOoutput{{nfact}}$KMO

```

### {{nfact}}-Factor: Post-Imputation Tests for Data Suitability for Factor Analysis
	
#### Bartlett's Test of Sphericity


``` {r, post-imputationCorrelationMatrix{{nfact}}, results="asis", echo=FALSE}
### generate polyserial correlation matrix
### set cor.smooth to TRUE to avoid having not positive definite matrix
postImputedCor{{nfact}} <- polychoric(imputedNumericDF{{nfact}},
                                       smooth=TRUE,
                                       correct = 0.01)
postImputedCor{{nfact}} <- round(postImputedCor{{nfact}}$rho, 3)

write.csv(postImputedCor{{nfact}}, file="data/postImputedCor2.2.{{nfact}}.csv")

```


``` {r, postImputationBartlett{{nfact}}, results="asis", echo=FALSE}

postBartlett{{nfact}} <- cortest.bartlett(postImputedCor{{nfact}}, 
n = nrow(ddOrd{{nfact}}))

```

This is a test that the matrix is an identity matrix. This would mean
that the correlations were not significantly different from 0.
If it's not significant, the matrix is not suitable because 
the variables show too little covariance.  
  


The chi-squared for the Bartlett test is 
`r postBartlett{{nfact}}$chisq` with
`r postBartlett{{nfact}}$df` DF, p = 
`r format(postBartlett{{nfact}}$p.value, scientific = TRUE)`.



#### {{nfact}}-Factor: Kaiser-Meyer-Olkin Criterion (KMO)

From EFAtools::KMO documentation:

> The KMO represents the degree to which each observed variable is predicted by the other variables in the dataset and with this indicates the suitability for factor analysis  

The numeric version of the dataset is used because stats::cor is used to find
the correlation and it requires numeric input. Used option for 
Spearman correlation because of ordered variables.  


``` {r, KMOpostImputed{{nfact}}, results="asis", echo=FALSE}
KMOutput{{nfact}} <- KMO(ddNum{{nfact}}, cor_method = "spearman")
KMOoutput{{nfact}}$KMO

```


### Between-Item Correlations


#### Pre-Imputation

For factor analysis, it is recommended that some of the item correlationsshould be 
between 0.3 and 0.9.
Polychoric correlations were computed using the `polychoric` function in the `psych` package in R 
with options `smooth = TRUE` to adjust for non-positive-definite matrices 
and `correct = 0.01` to avoid computation problems with covariance of zero.


The minimum correlation in this data set is `r min(lowerTriangle(preImputedCor{{nfact}}))`.
The maximum correlation in this data set is `r max(lowerTriangle(preImputedCor{{nfact}}))`.


``` {r, preImputedCor{{nfact}}, results="asis", echo=FALSE}
cor.plot(preImputedCor{{nfact}})

```
#### Post-Imputation

The post imputation polyserial correlation was also computed using the `polychoric`
function, with no setting `smooth = TRUE` and `correct = 0.01.`  

The minimum correlation was `r min(lowerTriangle(postImputedCor{{nfact}}))`.
The maximum correlation was `r max(lowerTriangle(postImputedCor{{nfact}}))`.

``` {r, postImputedCorrelation{{nfact}}, results="asis", echo=FALSE}
cor.plot(postImputedCor{{nfact}})
```

### Estimating Number of Factors

#### Parallel method

From the EFAtools documentation:

>Various methods for performing parallel analysis. This function uses future_lapply for which a parallel processing plan can be selected. To do so, call library(future) and, for example, plan(multisession); see examples.  

Settings Used:    
- n.obs = `r nrow(ddItems)`
- eigen_type = "EFA"
- fa = "fa" (factor analysis not PCA)
- fm = "wls" (weighted least squares because pa gave errors and weighted recommended for ordinal data.
- use = "all.obs" (since we have imputed missing values, we can use all data points)
- cor = "poly" (use polychoric correlation matrix)
- n.iter = 100 (run for 100 iterations)  


``` {r, parallelFactorestimation{{nfact}}, results=FALSE, echo=FALSE} 
parallelOutput{{nfact}} <- fa.parallel(imputedNumericDF{{nfact}},
                                fa = "fa",
                                fm = "pa",
                              n.iter = 100,
### argument not allowed                              smooth = TRUE)
                              correct = 0.01)
 

```

The suggested number of factors is `r parallelOutput{{nfact}}$nfact`.  

#### Minimum Average Partial

MAP is recommended as a way to find the number of factors when the items are ordinal. The lowest value indicates the best number of factors.  

``` {r, MAP{{nfact}}, results="asis", echo=FALSE}
mapFactors{{nfact}} <- vss(postImputedCor{{nfact}},
                           n.obs = nrow(ddNum{{nfact}}),
                  n = 18,
                  rotate = "oblimin",
                  fm="pa",
                  smooth = TRUE,
                  plot = FALSE,
				  cor = "poly",
                  maxit = 100000,
                  correct = 0.01)
 ### tried correction values pf 0.01. 0.05, 0.01, 0.015, 0.25, 0.3  because of error about c(x, y)

mapTab{{nfact}} <- data.frame(seq(1:length(mapFactors{{nfact}}$map)),
                              mapFactors{{nfact}}$map)
colnames(mapTab{{nfact}}) <- c("Number of Factors", "MAP value")

mapTabK{{nfact}} <- kable(mapTab{{nfact}}, digits = 5, row.names=FALSE)
kable_styling(mapTabK{{nfact}}, full_width = FALSE)

```

### Factor Analysis for {{nfact}} Factors

#### {{nfact}} Factors Model Fit

``` {r, modelFit{{nfact}}, eval=TRUE, echo=FALSE}

fanal{{nfact}} <- fa(imputedNumericDF{{nfact}},
      nfactors = {{nfact}},
      rotate = "oblimin",
      fm = "pa",
      smooth = TRUE,
      cor = "poly",
      correct = 0.01,
      max.iter = 100000)

save(fanal{{nfact}}, file = paste0("data/fanal2.2.", {{nfact}}, ".Rda"))

```

Although the chi-square test of goodness of fit is sensitive to departures from normality like
the C-BARQ items, Hopper et al (2008) recommend always reporting it.  

- chi-square: `r fanal{{nfact}}$STATISTIC`  
- degrees of freedom: `r fanal{{nfact}}$dof`  
- P-value for chi-square = `r format(fanal{{nfact}}$PVAL, scientific = TRUE)`  

Tucker-Lewis Index of Factoring Reliability/Non-Norm Fit Index:
`r fanal{{nfact}}$TLI`.
Should be > 0.9; need reference)


#### {{nfact}} Factor Model Communalities

``` {r, commun{{nfact}}, eval=TRUE, echo=FALSE}
comTab <- kable(data.frame(fanal{{nfact}}$communality), digits = 2)
kable_styling(comTab, full_width = FALSE)

```

#### How many communalities < 0.40?

There are `r length(fanal{{nfact}}[fanal{{nfact}}$communality < 0.40])` 
items with communality < 0.40.


``` {r, lowCommTab{{nfact}}, eval=TRUE, echo=FALSE}
lc{{nfact}} <- data.frame(fanal{{nfact}}$communality)
lc{{nfact}}$item <- colnames(ddOrd{{nfact}})
lc{{nfact}} <- lc{{nfact}}[lc{{nfact}}[1] < 0.40, ]
lcTab{{nfact}} <- kable(lc{{nfact}}, digits = 2)
kable_styling(lcTab{{nfact}})
datapath <- "data/"
## save(lc{{nfact}}, file=paste0(datapath, "lc2.", {{nfact}}, ".Rda"))

```

#### {{nfact}} Factor Model Loadings

``` {r, finalLoadings{{nfact}}, eval=TRUE, echo=FALSE}
loadMat <- matrix(fanal{{nfact}}$loadings, nrow = ncol(ddOrd{{nfact}}))
dimnames(loadMat) <- dimnames(fanal{{nfact}}$loadings)
loadingsTab <- kable(loadMat, digits = 2)
kable_styling(loadingsTab)

### calculate max loading for each item
loadDF <- data.frame(loadMat)
loadDF$maximum <- apply(loadDF, 1, max)
loadDF$largest <- colnames(loadDF)[apply(loadDF, 1, which.max)]
### sort df by factor
loadDF <- loadDF[order(loadDF$largest), ]
```

##### {{nfact}} Factor Model Largest Loading Per Item

``` {r, loadwithDesc{{nfact}}, eval=TRUE, echo=FALSE}
## merge description with loadings
loadDF$itemNames <- rownames(loadDF)
m1 <- merge(loadDF, descItems, by="itemNames", all.x=TRUE, all.y=FALSE)
### sort by factor 

m1 <- m1[order(m1$largest), ]
largestLoadings <- kable(m1[ ,c("largest", "maximum", "itemNames", "itemDescriptions")],
                         digits = 2,
      caption = "Largest Loading Per Item and Associated Factors, Sorted by Factor")
kable_styling(largestLoadings, full_width = FALSE)

```
### {{nfact}} Model Reliability Measures

``` {r, reliability{{nfact}}, eval = TRUE, echo=FALSE}
keys{{nfact}} <- factor2cluster(fanal{{nfact}})
keysList{{nfact}} <- keys2list(keys{{nfact}})

scores{{nfact}} <- scoreItems(keysList{{nfact}},
                              imputedNumericDF{{nfact}})

alphaTab <- kable(scores{{nfact}}$alpha, digits = 3)
kable_styling(alphaTab, full_width = FALSE)

```
*omega* is thought to be better measure of reliability than alpha, because it looks at the relationships between all the items rather than just the ones within each factor. It's different than alpha because it assumes that there is a genral factor, g, that all items have in common. This is listed as the first row of the table below.

There are three omegas for each factor:

* omega_total - total true score variance in factor   
* omega_hierarchical - variance attributable to general factor (g)  
* omega_subscale - variance attributable to the subscale   


From `EFAtools::OMEGA` documentation:  

Omegas refer to the correlation between a factor and a unit-weighted composite score and thus the true score variance in a unit-weighted composite based on the respective indicators. Omega total is the total true score variance in a composite. Omega hierarchical is the true score variance in a composite that is attributable to the general factor, and omega subscale is the true score variance in a composite attributable to all subscales / group factors (for the whole scale) or to the specific subscale / group factor (for subscale composites).


Interpretation of omega_subscale  

no universal guideline 

0.50 is minimum, 0.75 preferable
(watkins books,rodrigues16, zimbarg2005



``` {r, omegas{{nfact}}, eval=TRUE, echo=FALSE}

## rel{{nfact}} <- reliability(keysList{{nfact}},
##                             postImputedCor{{nfact}},
##                             split = FALSE)


## rel{{nfact}}

## get omegas
sl{{nfact}} <- SL(fanal{{nfact}}, method = "PAF", type = "psych")
om{{nfact}} <- OMEGA(sl{{nfact}}, type = "psych")
om{{nfact}}
```
